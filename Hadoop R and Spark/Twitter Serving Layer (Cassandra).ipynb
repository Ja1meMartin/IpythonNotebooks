{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load packages and init SQLContext:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SQLContext\n",
    "from pyspark.sql import functions as F\n",
    "sqlContext = SQLContext(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dataset = sqlContext.read.json(\"file:///home/bdm/twitter.small\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parse dates before we start processing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from operator import add\n",
    "\n",
    "def parse_date(date_field):\n",
    "    date_parts = date_field.split()\n",
    "    date_str = \"%s/%s/%s:%s\" % (date_parts[2],\n",
    "                                date_parts[1],\n",
    "                                date_parts[5],\n",
    "                                date_parts[3])\n",
    "    return datetime.strptime(date_str, '%d/%b/%Y:%H:%M:%S')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Register temp table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset.registerTempTable(\"tweets\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tweets-oriented"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tweets per day, month, year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+\n",
      "|      date|count|\n",
      "+----------+-----+\n",
      "|2012-11-16|    1|\n",
      "|2012-11-12|    1|\n",
      "|2011-01-18|    2|\n",
      "|2008-08-13|    1|\n",
      "|2010-11-30|    1|\n",
      "|2009-09-04|    1|\n",
      "|2010-04-03|    1|\n",
      "|2012-10-15|    1|\n",
      "|2012-03-13|    1|\n",
      "|2009-11-25|    1|\n",
      "|2010-11-03|    1|\n",
      "|2008-04-13|    1|\n",
      "|2010-11-25|    1|\n",
      "|2008-06-19|    1|\n",
      "|2009-06-12|    1|\n",
      "|2010-02-03|    1|\n",
      "|2009-02-21|    1|\n",
      "|2009-12-15|    1|\n",
      "|2009-10-08|    1|\n",
      "|2010-10-22|    1|\n",
      "+----------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tweets_per_day = dataset.map(lambda x: (parse_date(x.user.created_at).strftime(\"%Y-%m-%d\"), 1)).reduceByKey(add)\n",
    "countDF = sqlContext.createDataFrame(tweets_per_day).withColumnRenamed(\"_1\",\"date\").withColumnRenamed(\"_2\",\"count\")\n",
    "countDF.registerTempTable(\"tweetsCount\")\n",
    "sqlContext.sql(\"SELECT * from tweetsCount\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interactions per day, month, year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------+\n",
      "|      date|interactions|\n",
      "+----------+------------+\n",
      "|2012-11-16|           0|\n",
      "|2012-11-12|           1|\n",
      "|2011-01-18|           0|\n",
      "|2008-08-13|           0|\n",
      "|2010-11-30|           0|\n",
      "|2009-09-04|           0|\n",
      "|2010-04-03|           0|\n",
      "|2012-10-15|           0|\n",
      "|2012-03-13|           1|\n",
      "|2009-11-25|           0|\n",
      "|2010-11-03|           0|\n",
      "|2008-04-13|           0|\n",
      "|2010-11-25|           0|\n",
      "|2008-06-19|           0|\n",
      "|2009-06-12|           0|\n",
      "|2010-02-03|           0|\n",
      "|2009-02-21|           0|\n",
      "|2009-12-15|           0|\n",
      "|2009-10-08|           0|\n",
      "|2010-10-22|           0|\n",
      "+----------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "interactions_per_day = dataset.map(lambda x: (parse_date(x.user.created_at).strftime(\"%Y-%m-%d\")\\\n",
    "                                              , x.favorite_count + x.retweet_count)).reduceByKey(add)\n",
    "interactionsDF = sqlContext.createDataFrame(interactions_per_day).withColumnRenamed(\"_1\",\"date\")\\\n",
    "    .withColumnRenamed(\"_2\",\"interactions\") \n",
    "interactionsDF.registerTempTable(\"tweetInteractions\")\n",
    "sqlContext.sql(\"SELECT * from tweetInteractions\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Join Two Dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "userTweetsDF = sqlContext.sql(\"\"\"SELECT t1.date,\n",
    "           t1.count,\n",
    "           t2.interactions \n",
    "      FROM tweetInteractions t2\n",
    " LEFT JOIN tweetsCount t1 ON t2.date = t1.date\n",
    "UNION\n",
    "    SELECT t2.date,\n",
    "           t1.count,\n",
    "           t2.interactions\n",
    "      FROM tweetInteractions t2\n",
    "RIGHT JOIN tweetsCount t1 ON t2.date = t1.date\"\"\")\n",
    "userTweetsDF.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Table in Cassandra"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Keyspace and Table in Cassandra\n",
    "  \n",
    "CREATE KEYSPACE assignment\n",
    "WITH REPLICATION = { ’class’ : ’SimpleStrategy’, ’replication_factor’ : 1 };\n",
    "\n",
    "CREATE TABLE tweetInteractions (  \n",
    "date date PRIMARY KEY,  \n",
    "count int,  \n",
    "interactions int  \n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Write To Cassandra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "userTweetsDF.select(\"date\", \"count\", \"interactions\")\\  \n",
    ".write.format(\"org.apache.spark.sql.cassandra\")\\  \n",
    ".options(table=\"userTweets\", keyspace=\"assignment\")\\  \n",
    ".save(mode=\"append\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read from Cassandra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "userTweets = sql.read.format(\"org.apache.spark.sql.cassandra\")\\\n",
    ".load(keyspace=\"assignment\", table=\"userTweets\")\n",
    "\n",
    "userTweets.registerTempTable(\"userTweets\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Month With The Most Interactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sqlContext.sql(\n",
    "  \"\"\"SELECT YEAR(date) AS Year , month(date) AS Month, SUM(interactions) AS Interactions\n",
    "     FROM userTweets\n",
    "     GROUP BY Year(date) , Month(date)\n",
    "     ORDER BY Interactions DESC\n",
    "     LIMIT 1\n",
    "     \"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Movies-oriented"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tweets per movie per day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----------+-----+\n",
      "|               title|      date|count|\n",
      "+--------------------+----------+-----+\n",
      "|imdb.com/title/tt...|2009-11-01|    1|\n",
      "|imdb.com/title/tt...|2008-04-13|    1|\n",
      "|imdb.com/title/tt...|2010-02-24|    1|\n",
      "|imdb.com/title/tt...|2009-06-29|    1|\n",
      "|imdb.com/title/tt...|2009-03-17|    1|\n",
      "|imdb.com/title/tt...|2009-06-02|    1|\n",
      "|imdb.com/title/tt...|2010-03-20|    1|\n",
      "|imdb.com/title/tt...|2010-11-06|    1|\n",
      "|imdb.com/title/tt...|2009-06-09|    1|\n",
      "|imdb.com/title/tt...|2009-03-17|    1|\n",
      "|imdb.com/title/tt...|2011-01-25|    1|\n",
      "|imdb.com/title/tt...|2009-12-15|    1|\n",
      "|imdb.com/title/tt...|2009-02-21|    1|\n",
      "|imdb.com/title/tt...|2011-02-21|    1|\n",
      "|imdb.com/title/tt...|2012-11-12|    1|\n",
      "|imdb.com/title/tt...|2009-06-12|    1|\n",
      "|imdb.com/title/tt...|2008-06-19|    1|\n",
      "|imdb.com/title/tt...|2009-03-17|    1|\n",
      "|imdb.com/title/tt...|2010-09-14|    1|\n",
      "|imdb.com/title/tt...|2012-10-15|    1|\n",
      "+--------------------+----------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "movies_tweets_per_day = dataset.map(lambda x: ((x.entities.urls[0].display_url, parse_date(x.user.created_at).strftime(\"%Y-%m-%d\")), 1)).reduceByKey(add)\n",
    "movieCountsDF = sqlContext.createDataFrame(movies_tweets_per_day.map(lambda tup: (tup[0][0], tup[0][1], tup[1])))\\\n",
    "        .withColumnRenamed(\"_2\",\"date\").withColumnRenamed(\"_3\",\"count\").withColumnRenamed(\"_1\",\"title\")\n",
    "movieCountsDF.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Table in Cassandra"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CREATE TABLE movieCounts (  \n",
    "title text,  \n",
    "date date,  \n",
    "counts int,  \n",
    "primary key(title, date)  \n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Write To Cassandra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "movieCountsDF.select(\"title\", \"date\", \"counts\")\\  \n",
    ".write.format(\"org.apache.spark.sql.cassandra\")\\  \n",
    ".options(table=\"movieCounts\", keyspace=\"assignment\")\\  \n",
    ".save(mode=\"append\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read from Cassandra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "movieCounts = sql.read.format(\"org.apache.spark.sql.cassandra\")\\\n",
    ".load(keyspace=\"assignment\", table=\"movieCounts\")\n",
    "\n",
    "movieCounts.registerTempTable(\"popularity\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 20 Most Popular Movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sqlContext.sql(\"SELECT title,count from popularity ORDER BY count DESC\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Engagement per movie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----------+\n",
      "|               movie|engagement|\n",
      "+--------------------+----------+\n",
      "|imdb.com/title/tt...|         0|\n",
      "|imdb.com/title/tt...|         0|\n",
      "|imdb.com/title/tt...|         1|\n",
      "|imdb.com/title/tt...|         0|\n",
      "|imdb.com/title/tt...|         0|\n",
      "|imdb.com/title/tt...|         0|\n",
      "|imdb.com/title/tt...|         0|\n",
      "|imdb.com/title/tt...|         0|\n",
      "|imdb.com/title/tt...|         0|\n",
      "|imdb.com/title/tt...|         0|\n",
      "|imdb.com/title/tt...|         0|\n",
      "|imdb.com/title/tt...|         0|\n",
      "|imdb.com/title/tt...|         0|\n",
      "|imdb.com/title/tt...|         0|\n",
      "|imdb.com/title/tt...|         0|\n",
      "|imdb.com/title/tt...|         0|\n",
      "|imdb.com/title/tt...|         0|\n",
      "|imdb.com/title/tt...|         0|\n",
      "|imdb.com/title/tt...|         0|\n",
      "|imdb.com/title/tt...|         0|\n",
      "+--------------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "movies_engagement = sqlContext.sql(\"select entities.urls[0].display_url as movie, \"+\\\n",
    "               \"sum(favorite_count) + sum(retweet_count) as engagement \"\n",
    "               \"from tweets \"+\\\n",
    "               \"group by entities.urls[0].display_url\")\n",
    "\n",
    "movies_engagement.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Table in Cassandra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "CREATE TABLE movieEngagements (\n",
    "movie text PRIMARY KEY,\n",
    "engagements int\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Write To Cassandra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "movie_engagements.select(\"movie\", \"engagement\")\\  \n",
    ".write.format(\"org.apache.spark.sql.cassandra\")\\  \n",
    ".options(table=\"movieEngagements\", keyspace=\"assignment\")\\  \n",
    ".save(mode=\"append\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Read from Cassandra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "movieEngagements = sql.read.format(\"org.apache.spark.sql.cassandra\")\\\n",
    ".load(keyspace=\"assignment\", table=\"movieEngagements\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Popularity per movie per language:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------+---+\n",
      "|               movie|language|pop|\n",
      "+--------------------+--------+---+\n",
      "|imdb.com/title/tt...|      en|  1|\n",
      "|imdb.com/title/tt...|      en|  1|\n",
      "|imdb.com/title/tt...|      en|  1|\n",
      "|imdb.com/title/tt...|      en|  1|\n",
      "|imdb.com/title/tt...|      en|  1|\n",
      "|imdb.com/title/tt...|      da|  1|\n",
      "|imdb.com/title/tt...|      en|  1|\n",
      "|imdb.com/title/tt...|      en|  1|\n",
      "|imdb.com/title/tt...|      en|  1|\n",
      "|imdb.com/title/tt...|      en|  1|\n",
      "|imdb.com/title/tt...|      en|  1|\n",
      "|imdb.com/title/tt...|      en|  1|\n",
      "|imdb.com/title/tt...|      en|  1|\n",
      "|imdb.com/title/tt...|      en|  1|\n",
      "|imdb.com/title/tt...|      en|  1|\n",
      "|imdb.com/title/tt...|      en|  1|\n",
      "|imdb.com/title/tt...|      en|  1|\n",
      "|imdb.com/title/tt...|      sk|  1|\n",
      "|imdb.com/title/tt...|      en|  1|\n",
      "|imdb.com/title/tt...|      en|  1|\n",
      "+--------------------+--------+---+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "movies_language_pop = sqlContext.sql(\"select entities.urls[0].display_url as movie, \"+\\\n",
    "               \"lang as language, count(1) as pop \"\n",
    "               \"from tweets \"+\\\n",
    "               \"group by entities.urls[0].display_url, lang\")\n",
    "\n",
    "\n",
    "\n",
    "movies_language_pop.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Table in Cassandra"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CREATE TABLE moviePopularity (  \n",
    "movie text PRIMARY KEY,  \n",
    "language varchar(2),  \n",
    "pop int  \n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write To Cassandra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "movie_languages_pop.select(\"movie\", \"language\", \"pop\")\\  \n",
    ".write.format(\"org.apache.spark.sql.cassandra\")\\  \n",
    ".options(table=\"moviePopularity\", keyspace=\"assignment\")\\  \n",
    ".save(mode=\"append\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read from Cassandra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "moviePopularity = sql.read.format(\"org.apache.spark.sql.cassandra\")\\\n",
    ".load(keyspace=\"assignment\", table=\"moviePopularity\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Film Most Tweeted About in Spanish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "moviePopularity.registerTempTable(\"lang\")\n",
    "sqlContext.sql(\"\"\"\n",
    "SELECT movie, language, SUM(pop) AS count FROM lang\n",
    "WHERE language = 'en'\n",
    "GROUP BY movie, language\n",
    "ORDER BY count DESC\n",
    "LIMIT 1\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Users-oriented"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Number of followers, favourites, statuses and listings per user, at different time points:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+--------------------+---------+----+--------+------+\n",
      "|       username|           createdAt|followers|favs|statuses|listed|\n",
      "+---------------+--------------------+---------+----+--------+------+\n",
      "|     Nat_ta_gun|Thu Feb 28 14:43:...|      114| 679|   47133|     2|\n",
      "|   Carterwade99|Thu Feb 28 14:47:...|      151| 121|    9281|     0|\n",
      "|       MircheBg|Thu Feb 28 14:58:...|      201| 333|    1410|     6|\n",
      "|     zoltanmora|Thu Feb 28 15:00:...|       81|  23|     853|     1|\n",
      "|     zoltanmora|Thu Feb 28 15:04:...|       81|  23|     853|     1|\n",
      "|        yenda_m|Thu Feb 28 15:05:...|       75|   0|     655|     1|\n",
      "|     zoltanmora|Thu Feb 28 15:07:...|       81|  23|     853|     1|\n",
      "|        BaderJr|Thu Feb 28 15:08:...|      137|  76|    8231|     0|\n",
      "|      paulpasia|Thu Feb 28 15:09:...|      215|  15|    1091|     4|\n",
      "|         MMTA7W|Thu Feb 28 15:26:...|      130| 135|   22372|     0|\n",
      "|         MMTA7W|Thu Feb 28 15:27:...|      130| 135|   22372|     0|\n",
      "|         MMTA7W|Thu Feb 28 15:28:...|      130| 135|   22372|     0|\n",
      "|   DaywalkerXKR|Thu Feb 28 15:39:...|      843| 523|   23235|    13|\n",
      "| thegreatnausea|Thu Feb 28 15:41:...|      253|  51|    8212|     2|\n",
      "|  laurencendall|Thu Feb 28 15:41:...|      153|  68|    3622|     0|\n",
      "|         sacidu|Thu Feb 28 15:43:...|      200|  49|   18908|     5|\n",
      "|Mikael_Nihilsen|Thu Feb 28 15:45:...|      111|  12|    2835|     3|\n",
      "|   Carterwade99|Thu Feb 28 15:48:...|      151| 121|    9281|     0|\n",
      "|        cthies2|Thu Feb 28 15:49:...|      141| 376|    6852|     2|\n",
      "|    TrojanBeatz|Thu Feb 28 15:56:...|      126|  15|    2395|     1|\n",
      "+---------------+--------------------+---------+----+--------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "user_stats = dataset.map(lambda x: (x.user.screen_name, \\\n",
    "    x.created_at, x.user.followers_count, x.user.favourites_count, x.user.statuses_count, x.user.listed_count))\n",
    "usersDF = sqlContext.createDataFrame(user_stats).withColumnRenamed(\"_1\",\"username\")\\\n",
    "    .withColumnRenamed(\"_2\",\"createdAt\") \\\n",
    "    .withColumnRenamed(\"_4\",\"favs\")\\\n",
    "    .withColumnRenamed(\"_5\",\"statuses\") \\\n",
    "    .withColumnRenamed(\"_3\",\"followers\")\\\n",
    "    .withColumnRenamed(\"_6\",\"listed\") \n",
    "\n",
    "usersDF.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Table in Cassandra"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CREATE TABLE users (  \n",
    "username text,  \n",
    "createdAt varchar(30),  \n",
    "followers int,  \n",
    "favs int,  \n",
    "statuses int,  \n",
    "listed int,  \n",
    "primary key (username, createdAt)  \n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write To Cassandra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "usersDF.select(\"username\", \"createdAt\", \"favs\", \"statuses\", \"followers\", \"listed\")\\  \n",
    ".write.format(\"org.apache.spark.sql.cassandra\")\\  \n",
    ".options(table=\"users\", keyspace=\"assignment\")\\  \n",
    ".save(mode=\"append\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read from Cassandra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "users = sql.read.format(\"org.apache.spark.sql.cassandra\")\\\n",
    ".load(keyspace=\"assignment\", table=\"users\")\n",
    "\n",
    "users.registerTemporaryTable(\"users\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Latest update of the user with the most followers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sqlContext.sql(\"\"\"select u.*\n",
    "from users u\n",
    "Join\n",
    "(\n",
    "    select  t.Username, max(followers) AS maximum\n",
    "    from   users t\n",
    "    group by t.Username\n",
    "    order by maximum desc limit 1\n",
    ")   p\n",
    "On u.Username = p.Username\n",
    "Order By u.Date DESC\n",
    "Limit 1\"\"\").show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pySpark (Spark 1.6.0)",
   "language": "python",
   "name": "pyspark"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
