{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process Stop Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stop_words = \"\"\"\n",
    "a about above across adj after again against all almost alone along also although always am among\n",
    "an and another any anybody anyone anything anywhere apart are around as aside at away be\n",
    "because been before behind being below besides between beyond both but by can cannot could\n",
    "deep did do does doing done down downwards during each either else enough etc even ever every\n",
    "everybody everyone except far few for forth from get gets got had hardly has have having her here\n",
    "herself him himself his how however i if in indeed instead into inward is it its itself just kept many\n",
    "maybe might mine more most mostly much must myself near neither next no nobody none nor not\n",
    "nothing nowhere of off often on only onto or other others ought our ours out outside over own p\n",
    "per please plus pp quite rather really said seem self selves several shall she should since so some\n",
    "somebody somewhat still such than that the their theirs them themselves then there therefore\n",
    "these they this thorough thoroughly those through thus to together too toward towards under until\n",
    "up upon v very was well were what whatever when whenever where whether which while who\n",
    "whom whose will with within without would yet young your yourself\n",
    "\"\"\".split()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split Corpus into Lines and Check for Whitespace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Doc1= English Language and Written Rules.---\n",
      "---Doc2= Semantic Indexing made easy.---\n",
      "---Doc3= Information Retrieval is fun!---\n",
      "---Doc4= Writing English essays and academic papers for beginners.---\n",
      "---Doc5= Retrieving Information from semantically diverse documents.---\n",
      "---Doc6= Learn how to Index written textbooks.---\n"
     ]
    }
   ],
   "source": [
    "corpus = \"\"\"\n",
    "Doc1= English Language and Written Rules.\n",
    "\n",
    "Doc2= Semantic Indexing made easy.\n",
    "\n",
    "Doc3= Information Retrieval is fun!\n",
    "\n",
    "Doc4= Writing English essays and academic papers for beginners.\n",
    "\n",
    "Doc5= Retrieving Information from semantically diverse documents.\n",
    "\n",
    "Doc6= Learn how to Index written textbooks.\n",
    "\"\"\"\n",
    "\n",
    "corpus = [c for c in corpus.split(\"\\n\") if c]\n",
    "\n",
    "# Check no blank lines\n",
    "# I often surround things with \"---\" to check for whitespace\n",
    "for c in corpus:\n",
    "    print \"---\"+c+\"---\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test process text False\n"
     ]
    }
   ],
   "source": [
    "def process_text(sentence):\n",
    "    '''\n",
    "        Prepare words to be processed by:\n",
    "            - making lowercase\n",
    "            - splitting on space\n",
    "            - removing stop words\n",
    "            - removing punctuation from end of word\n",
    "            - remove empty strings\n",
    "            - remove unique words with set\n",
    "            \n",
    "        Q. Do I want to return a set or list?\n",
    "    '''\n",
    "    def remove_punctuation(word):\n",
    "        '''\n",
    "            If the last digit is not alpha then remove it\n",
    "            Assumption: no numbers\n",
    "        '''\n",
    "        \n",
    "        if not word[-1].isalpha():\n",
    "            word = word[:-1]\n",
    "            \n",
    "        return word\n",
    "    \n",
    "    sentence = sentence.lower()\n",
    "    words = [remove_punctuation(w) for w in sentence.split() if w not in stop_words]\n",
    "    \n",
    "    # remove empty words\n",
    "    # use set to remove unique words\n",
    "    return {w for w in words if w}\n",
    "    \n",
    "\n",
    "\n",
    "print \"Test process text\", process_text(\"A mad - MAn!\") == ['mad', 'man']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document: Doc1\n",
      "Text: ---English Language and Written Rules.---\n",
      "rules\n",
      "written\n",
      "language\n",
      "english\n",
      "Document: Doc2\n",
      "Text: ---Semantic Indexing made easy.---\n",
      "indexing\n",
      "made\n",
      "semantic\n",
      "easy\n",
      "Document: Doc3\n",
      "Text: ---Information Retrieval is fun!---\n",
      "fun\n",
      "information\n",
      "retrieval\n",
      "Document: Doc4\n",
      "Text: ---Writing English essays and academic papers for beginners.---\n",
      "papers\n",
      "writing\n",
      "beginners\n",
      "academic\n",
      "english\n",
      "essays\n",
      "Document: Doc5\n",
      "Text: ---Retrieving Information from semantically diverse documents.---\n",
      "information\n",
      "semantically\n",
      "diverse\n",
      "documents\n",
      "retrieving\n",
      "Document: Doc6\n",
      "Text: ---Learn how to Index written textbooks.---\n",
      "textbooks\n",
      "index\n",
      "written\n",
      "learn\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "index = defaultdict(set)\n",
    "\n",
    "for c in corpus:    \n",
    "    # Will split on \"= \" but better not to assume spaces will always be there\n",
    "    document, text = c.split(\"= \")\n",
    "    print \"Document:\", document\n",
    "    print \"Text:\", \"---\"+text+\"---\"\n",
    "    for word in process_text(text):\n",
    "        print word\n",
    "        index[word].add(document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(<type 'set'>, {'semantic': set(['Doc2']), 'diverse': set(['Doc5']), 'information': set(['Doc3', 'Doc5']), 'documents': set(['Doc5']), 'retrieving': set(['Doc5']), 'writing': set(['Doc4']), 'written': set(['Doc1', 'Doc6']), 'easy': set(['Doc2']), 'papers': set(['Doc4']), 'semantically': set(['Doc5']), 'index': set(['Doc6']), 'rules': set(['Doc1']), 'learn': set(['Doc6']), 'indexing': set(['Doc2']), 'beginners': set(['Doc4']), 'essays': set(['Doc4']), 'made': set(['Doc2']), 'language': set(['Doc1']), 'textbooks': set(['Doc6']), 'academic': set(['Doc4']), 'english': set(['Doc1', 'Doc4']), 'fun': set(['Doc3']), 'retrieval': set(['Doc3'])})\n"
     ]
    }
   ],
   "source": [
    "print index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perform Boolean Operations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Search for 'English'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Doc1', 'Doc4'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index['english']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Search for 'Index'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Doc6'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index['index']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Search for 'Write AND English'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "set()"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index['write'] & index ['english']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Search for 'Retrieve AND Information'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "set()"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index['retrieve'] & index ['information']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Search for 'Fun OR English'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Doc1', 'Doc3', 'Doc4'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index['fun'] | index ['english']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Search for 'English OR Information BUT NOT Write'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set(['Doc1', 'Doc4'])\n",
      "set(['Doc3', 'Doc5'])\n",
      "set([])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Doc1', 'Doc3', 'Doc4', 'Doc5'}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print index['english']\n",
    "print index['information']\n",
    "print index['write']\n",
    "\n",
    "{doc for doc in (index['english'] | index['information']) if doc not in index['write'] }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Search for 'Index OR Semantic BUT NOT Easy OR Information'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set(['Doc2', 'Doc6'])\n",
      "set(['Doc2', 'Doc3', 'Doc5'])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Doc6']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print index['index'] | index['semantic']\n",
    "print index['easy']  | index['information']\n",
    "\n",
    "[doc for doc in (index['index'] | index['semantic']) if doc not in (index['easy'] | index['information']) ]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
